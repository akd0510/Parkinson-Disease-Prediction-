{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = \"E:/project/Parkinson's Project/CSV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total numbers of files are:  306\n",
      "Total numbers of Controlled Patients files are:  92\n",
      "Total numbers of Parkinson's Patients files are:  214\n"
     ]
    }
   ],
   "source": [
    "total_files = 0\n",
    "total_controlled_patients_files = 0\n",
    "total_parkinsons_patients_files = 0\n",
    "totalFiles = []\n",
    "Co_files = []\n",
    "Pt_files = []\n",
    "for files in os.listdir(loc):\n",
    "    if \"Pt\" or \"Co\" in files:\n",
    "        total_files = total_files + 1\n",
    "        totalFiles.append(files)\n",
    "    if \"Co\" in files:\n",
    "        total_controlled_patients_files = total_controlled_patients_files + 1\n",
    "        Co_files.append(files)\n",
    "    if \"Pt\" in files:\n",
    "        total_parkinsons_patients_files = total_parkinsons_patients_files + 1\n",
    "        Pt_files.append(files)\n",
    "print(\"Total numbers of files are: \",total_files)\n",
    "print(\"Total numbers of Controlled Patients files are: \",total_controlled_patients_files)\n",
    "print(\"Total numbers of Parkinson's Patients files are: \",total_parkinsons_patients_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time(sec)</th>\n",
       "      <th>VGRF_left_s1</th>\n",
       "      <th>VGRF_left_s2</th>\n",
       "      <th>VGRF_left_s3</th>\n",
       "      <th>VGRF_left_s4</th>\n",
       "      <th>VGRF_left_s5</th>\n",
       "      <th>VGRF_left_s6</th>\n",
       "      <th>VGRF_left_s7</th>\n",
       "      <th>VGRF_left_s8</th>\n",
       "      <th>VGRF_right_s1</th>\n",
       "      <th>VGRF_right_s2</th>\n",
       "      <th>VGRF_right_s3</th>\n",
       "      <th>VGRF_right_s4</th>\n",
       "      <th>VGRF_right_s5</th>\n",
       "      <th>VGRF_right_s6</th>\n",
       "      <th>VGRF_right_s7</th>\n",
       "      <th>VGRF_right_s8</th>\n",
       "      <th>Total_force_left</th>\n",
       "      <th>Total_force_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>199.1</td>\n",
       "      <td>87.34</td>\n",
       "      <td>91.08</td>\n",
       "      <td>24.09</td>\n",
       "      <td>21.12</td>\n",
       "      <td>87.67</td>\n",
       "      <td>87.23</td>\n",
       "      <td>64.57</td>\n",
       "      <td>163.9</td>\n",
       "      <td>79.86</td>\n",
       "      <td>112.42</td>\n",
       "      <td>50.82</td>\n",
       "      <td>13.75</td>\n",
       "      <td>102.74</td>\n",
       "      <td>144.98</td>\n",
       "      <td>79.53</td>\n",
       "      <td>662.20</td>\n",
       "      <td>748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>199.1</td>\n",
       "      <td>87.34</td>\n",
       "      <td>91.08</td>\n",
       "      <td>24.09</td>\n",
       "      <td>21.12</td>\n",
       "      <td>87.67</td>\n",
       "      <td>87.23</td>\n",
       "      <td>62.59</td>\n",
       "      <td>163.9</td>\n",
       "      <td>79.86</td>\n",
       "      <td>112.42</td>\n",
       "      <td>50.82</td>\n",
       "      <td>13.75</td>\n",
       "      <td>102.74</td>\n",
       "      <td>144.98</td>\n",
       "      <td>79.53</td>\n",
       "      <td>660.22</td>\n",
       "      <td>748.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>199.1</td>\n",
       "      <td>87.34</td>\n",
       "      <td>91.08</td>\n",
       "      <td>24.09</td>\n",
       "      <td>21.12</td>\n",
       "      <td>87.67</td>\n",
       "      <td>89.10</td>\n",
       "      <td>64.57</td>\n",
       "      <td>163.9</td>\n",
       "      <td>77.55</td>\n",
       "      <td>112.42</td>\n",
       "      <td>48.07</td>\n",
       "      <td>13.75</td>\n",
       "      <td>105.49</td>\n",
       "      <td>144.98</td>\n",
       "      <td>79.53</td>\n",
       "      <td>664.07</td>\n",
       "      <td>745.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>199.1</td>\n",
       "      <td>87.34</td>\n",
       "      <td>91.08</td>\n",
       "      <td>24.09</td>\n",
       "      <td>21.12</td>\n",
       "      <td>87.67</td>\n",
       "      <td>87.23</td>\n",
       "      <td>62.59</td>\n",
       "      <td>163.9</td>\n",
       "      <td>77.55</td>\n",
       "      <td>112.42</td>\n",
       "      <td>50.82</td>\n",
       "      <td>13.75</td>\n",
       "      <td>105.49</td>\n",
       "      <td>144.98</td>\n",
       "      <td>79.53</td>\n",
       "      <td>660.22</td>\n",
       "      <td>748.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>199.1</td>\n",
       "      <td>87.34</td>\n",
       "      <td>91.08</td>\n",
       "      <td>24.09</td>\n",
       "      <td>19.03</td>\n",
       "      <td>87.67</td>\n",
       "      <td>89.10</td>\n",
       "      <td>62.59</td>\n",
       "      <td>163.9</td>\n",
       "      <td>77.55</td>\n",
       "      <td>112.42</td>\n",
       "      <td>50.82</td>\n",
       "      <td>13.75</td>\n",
       "      <td>102.74</td>\n",
       "      <td>144.98</td>\n",
       "      <td>79.53</td>\n",
       "      <td>660.00</td>\n",
       "      <td>745.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time(sec)  VGRF_left_s1  VGRF_left_s2  VGRF_left_s3  VGRF_left_s4  \\\n",
       "0       0.01         199.1         87.34         91.08         24.09   \n",
       "1       0.02         199.1         87.34         91.08         24.09   \n",
       "2       0.03         199.1         87.34         91.08         24.09   \n",
       "3       0.04         199.1         87.34         91.08         24.09   \n",
       "4       0.05         199.1         87.34         91.08         24.09   \n",
       "\n",
       "   VGRF_left_s5  VGRF_left_s6  VGRF_left_s7  VGRF_left_s8  VGRF_right_s1  \\\n",
       "0         21.12         87.67         87.23         64.57          163.9   \n",
       "1         21.12         87.67         87.23         62.59          163.9   \n",
       "2         21.12         87.67         89.10         64.57          163.9   \n",
       "3         21.12         87.67         87.23         62.59          163.9   \n",
       "4         19.03         87.67         89.10         62.59          163.9   \n",
       "\n",
       "   VGRF_right_s2  VGRF_right_s3  VGRF_right_s4  VGRF_right_s5  VGRF_right_s6  \\\n",
       "0          79.86         112.42          50.82          13.75         102.74   \n",
       "1          79.86         112.42          50.82          13.75         102.74   \n",
       "2          77.55         112.42          48.07          13.75         105.49   \n",
       "3          77.55         112.42          50.82          13.75         105.49   \n",
       "4          77.55         112.42          50.82          13.75         102.74   \n",
       "\n",
       "   VGRF_right_s7  VGRF_right_s8  Total_force_left  Total_force_right  \n",
       "0         144.98          79.53            662.20             748.00  \n",
       "1         144.98          79.53            660.22             748.00  \n",
       "2         144.98          79.53            664.07             745.69  \n",
       "3         144.98          79.53            660.22             748.44  \n",
       "4         144.98          79.53            660.00             745.69  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCo = pd.read_csv(loc+ \"/\" + Co_files[0])\n",
    "dfCo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time(sec)</th>\n",
       "      <th>VGRF_left_s1</th>\n",
       "      <th>VGRF_left_s2</th>\n",
       "      <th>VGRF_left_s3</th>\n",
       "      <th>VGRF_left_s4</th>\n",
       "      <th>VGRF_left_s5</th>\n",
       "      <th>VGRF_left_s6</th>\n",
       "      <th>VGRF_left_s7</th>\n",
       "      <th>VGRF_left_s8</th>\n",
       "      <th>VGRF_right_s1</th>\n",
       "      <th>VGRF_right_s2</th>\n",
       "      <th>VGRF_right_s3</th>\n",
       "      <th>VGRF_right_s4</th>\n",
       "      <th>VGRF_right_s5</th>\n",
       "      <th>VGRF_right_s6</th>\n",
       "      <th>VGRF_right_s7</th>\n",
       "      <th>VGRF_right_s8</th>\n",
       "      <th>Total_force_left</th>\n",
       "      <th>Total_force_right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>71.72</td>\n",
       "      <td>174.90</td>\n",
       "      <td>135.96</td>\n",
       "      <td>83.38</td>\n",
       "      <td>30.14</td>\n",
       "      <td>64.57</td>\n",
       "      <td>84.04</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>679.91</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>71.72</td>\n",
       "      <td>173.25</td>\n",
       "      <td>134.31</td>\n",
       "      <td>84.92</td>\n",
       "      <td>31.68</td>\n",
       "      <td>64.57</td>\n",
       "      <td>87.78</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>68.53</td>\n",
       "      <td>169.84</td>\n",
       "      <td>132.55</td>\n",
       "      <td>86.46</td>\n",
       "      <td>31.68</td>\n",
       "      <td>67.43</td>\n",
       "      <td>87.78</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>683.87</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>65.34</td>\n",
       "      <td>168.19</td>\n",
       "      <td>132.55</td>\n",
       "      <td>86.46</td>\n",
       "      <td>31.68</td>\n",
       "      <td>67.43</td>\n",
       "      <td>91.52</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>682.77</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>62.15</td>\n",
       "      <td>165.00</td>\n",
       "      <td>129.03</td>\n",
       "      <td>88.11</td>\n",
       "      <td>31.68</td>\n",
       "      <td>70.40</td>\n",
       "      <td>95.26</td>\n",
       "      <td>39.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>681.23</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time(sec)  VGRF_left_s1  VGRF_left_s2  VGRF_left_s3  VGRF_left_s4  \\\n",
       "0       0.01         71.72        174.90        135.96         83.38   \n",
       "1       0.02         71.72        173.25        134.31         84.92   \n",
       "2       0.03         68.53        169.84        132.55         86.46   \n",
       "3       0.04         65.34        168.19        132.55         86.46   \n",
       "4       0.05         62.15        165.00        129.03         88.11   \n",
       "\n",
       "   VGRF_left_s5  VGRF_left_s6  VGRF_left_s7  VGRF_left_s8  VGRF_right_s1  \\\n",
       "0         30.14         64.57         84.04          35.2            0.0   \n",
       "1         31.68         64.57         87.78          35.2            0.0   \n",
       "2         31.68         67.43         87.78          39.6            0.0   \n",
       "3         31.68         67.43         91.52          39.6            0.0   \n",
       "4         31.68         70.40         95.26          39.6            0.0   \n",
       "\n",
       "   VGRF_right_s2  VGRF_right_s3  VGRF_right_s4  VGRF_right_s5  VGRF_right_s6  \\\n",
       "0            0.0            0.0            0.0            0.0            0.0   \n",
       "1            0.0            0.0            0.0            0.0            0.0   \n",
       "2            0.0            0.0            0.0            0.0            0.0   \n",
       "3            0.0            0.0            0.0            0.0            0.0   \n",
       "4            0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   VGRF_right_s7  VGRF_right_s8  Total_force_left  Total_force_right  \n",
       "0            0.0            0.0            679.91                0.0  \n",
       "1            0.0            0.0            683.43                0.0  \n",
       "2            0.0            0.0            683.87                0.0  \n",
       "3            0.0            0.0            682.77                0.0  \n",
       "4            0.0            0.0            681.23                0.0  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPt = pd.read_csv(loc + \"/\" + Pt_files[0])\n",
    "dfPt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Mean of Each Text File and converting a Text File to row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = []\n",
    "mean_time = []\n",
    "mean_VGRF_left1 = []\n",
    "mean_VGRF_left2 = []\n",
    "mean_VGRF_left3 = []\n",
    "mean_VGRF_left4 = []\n",
    "mean_VGRF_left5 = []\n",
    "mean_VGRF_left6 = []\n",
    "mean_VGRF_left7 = []\n",
    "mean_VGRF_left8 = []\n",
    "mean_VGRF_right1 = []\n",
    "mean_VGRF_right2 = []\n",
    "mean_VGRF_right3 = []\n",
    "mean_VGRF_right4 = []\n",
    "mean_VGRF_right5 = []\n",
    "mean_VGRF_right6 = []\n",
    "mean_VGRF_right7 = []\n",
    "mean_VGRF_right8 = []\n",
    "sum_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "for files in totalFiles:\n",
    "    if \"Co\" in files:\n",
    "        patient.append(0)\n",
    "    else:\n",
    "        patient.append(1)\n",
    "    df = pd.read_csv(loc + \"/\" + files)\n",
    "    \n",
    "    for cols in df['Time(sec)']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_time.append(sum_/len(df['Time(sec)']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s1']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left1.append(sum_/len(df['VGRF_left_s1']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s2']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left2.append(sum_/len(df['VGRF_left_s2']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s3']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left3.append(sum_/len(df['VGRF_left_s3']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s4']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left4.append(sum_/len(df['VGRF_left_s4']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s5']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left5.append(sum_/len(df['VGRF_left_s5']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s6']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left6.append(sum_/len(df['VGRF_left_s6']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s7']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left7.append(sum_/len(df['VGRF_left_s7']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_left_s8']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_left8.append(sum_/len(df['VGRF_left_s8']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s1']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right1.append(sum_/len(df['VGRF_right_s1']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s2']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right2.append(sum_/len(df['VGRF_right_s2']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s3']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right3.append(sum_/len(df['VGRF_right_s3']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s4']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right4.append(sum_/len(df['VGRF_right_s4']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s5']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right5.append(sum_/len(df['VGRF_right_s5']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s6']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right6.append(sum_/len(df['VGRF_right_s6']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s7']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right7.append(sum_/len(df['VGRF_right_s7']))\n",
    "    sum_ = 0\n",
    "    for cols in df['VGRF_right_s8']:\n",
    "        sum_ = sum_ + cols\n",
    "    mean_VGRF_right8.append(sum_/len(df['VGRF_right_s8']))\n",
    "    sum_ = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Values Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_dataframe = {\n",
    "    \"Patient\" : patient,\n",
    "    \"Mean Time\": mean_time,\n",
    "    \"Mean VGFR_left_s1\": mean_VGRF_left1, \"Mean VGFR_left_s2\": mean_VGRF_left2, \"Mean VGFR_left_s3\": mean_VGRF_left3,\n",
    "    \"Mean VGFR_left_s4\": mean_VGRF_left4, \"Mean VGFR_left_s5\": mean_VGRF_left5, \"Mean VGFR_left_s6\": mean_VGRF_left6,\n",
    "    \"Mean VGFR_left_s7\": mean_VGRF_left7, \"Mean VGFR_left_s8\": mean_VGRF_left8,\n",
    "    \"Mean VGFR_right_s1\": mean_VGRF_right1, \"Mean VGFR_right_s2\": mean_VGRF_right2, \"Mean VGFR_right_s3\": mean_VGRF_right3,\n",
    "    \"Mean VGFR_right_s4\": mean_VGRF_right4, \"Mean VGFR_right_s5\": mean_VGRF_right5, \"Mean VGFR_right_s6\": mean_VGRF_right6,\n",
    "    \"Mean VGFR_right_s7\": mean_VGRF_right7, \"Mean VGFR_right_s8\": mean_VGRF_right8}\n",
    "main_df = pd.DataFrame(dict_of_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Mean Time</th>\n",
       "      <th>Mean VGFR_left_s1</th>\n",
       "      <th>Mean VGFR_left_s2</th>\n",
       "      <th>Mean VGFR_left_s3</th>\n",
       "      <th>Mean VGFR_left_s4</th>\n",
       "      <th>Mean VGFR_left_s5</th>\n",
       "      <th>Mean VGFR_left_s6</th>\n",
       "      <th>Mean VGFR_left_s7</th>\n",
       "      <th>Mean VGFR_left_s8</th>\n",
       "      <th>Mean VGFR_right_s1</th>\n",
       "      <th>Mean VGFR_right_s2</th>\n",
       "      <th>Mean VGFR_right_s3</th>\n",
       "      <th>Mean VGFR_right_s4</th>\n",
       "      <th>Mean VGFR_right_s5</th>\n",
       "      <th>Mean VGFR_right_s6</th>\n",
       "      <th>Mean VGFR_right_s7</th>\n",
       "      <th>Mean VGFR_right_s8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>118.051940</td>\n",
       "      <td>68.692077</td>\n",
       "      <td>48.425916</td>\n",
       "      <td>43.703414</td>\n",
       "      <td>20.648383</td>\n",
       "      <td>94.384729</td>\n",
       "      <td>93.851677</td>\n",
       "      <td>32.885407</td>\n",
       "      <td>100.967355</td>\n",
       "      <td>61.528515</td>\n",
       "      <td>51.848497</td>\n",
       "      <td>70.042432</td>\n",
       "      <td>16.359854</td>\n",
       "      <td>104.850143</td>\n",
       "      <td>114.499416</td>\n",
       "      <td>43.202804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>111.420777</td>\n",
       "      <td>84.344456</td>\n",
       "      <td>67.783647</td>\n",
       "      <td>44.369387</td>\n",
       "      <td>5.277250</td>\n",
       "      <td>78.684485</td>\n",
       "      <td>28.449642</td>\n",
       "      <td>20.862919</td>\n",
       "      <td>94.473515</td>\n",
       "      <td>62.610805</td>\n",
       "      <td>59.430945</td>\n",
       "      <td>47.720293</td>\n",
       "      <td>6.488666</td>\n",
       "      <td>90.836907</td>\n",
       "      <td>55.465798</td>\n",
       "      <td>30.942615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>103.878062</td>\n",
       "      <td>84.826031</td>\n",
       "      <td>62.567225</td>\n",
       "      <td>45.874475</td>\n",
       "      <td>8.007434</td>\n",
       "      <td>71.013270</td>\n",
       "      <td>30.271631</td>\n",
       "      <td>22.709544</td>\n",
       "      <td>87.211491</td>\n",
       "      <td>70.739540</td>\n",
       "      <td>53.453065</td>\n",
       "      <td>55.558587</td>\n",
       "      <td>9.545464</td>\n",
       "      <td>83.647538</td>\n",
       "      <td>56.830314</td>\n",
       "      <td>32.571147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>87.844976</td>\n",
       "      <td>70.259019</td>\n",
       "      <td>86.646486</td>\n",
       "      <td>90.969328</td>\n",
       "      <td>12.027907</td>\n",
       "      <td>92.903315</td>\n",
       "      <td>109.522665</td>\n",
       "      <td>50.506421</td>\n",
       "      <td>115.009085</td>\n",
       "      <td>82.005218</td>\n",
       "      <td>67.853397</td>\n",
       "      <td>100.646351</td>\n",
       "      <td>28.439566</td>\n",
       "      <td>64.241570</td>\n",
       "      <td>91.184290</td>\n",
       "      <td>41.847457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>102.242404</td>\n",
       "      <td>79.036543</td>\n",
       "      <td>81.320073</td>\n",
       "      <td>98.200889</td>\n",
       "      <td>13.159388</td>\n",
       "      <td>92.903569</td>\n",
       "      <td>101.985595</td>\n",
       "      <td>47.110582</td>\n",
       "      <td>111.480607</td>\n",
       "      <td>101.130204</td>\n",
       "      <td>54.169980</td>\n",
       "      <td>107.104625</td>\n",
       "      <td>23.475233</td>\n",
       "      <td>78.174462</td>\n",
       "      <td>87.135885</td>\n",
       "      <td>39.752083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>32.261054</td>\n",
       "      <td>62.842370</td>\n",
       "      <td>59.733458</td>\n",
       "      <td>53.399572</td>\n",
       "      <td>75.651052</td>\n",
       "      <td>32.047481</td>\n",
       "      <td>63.601250</td>\n",
       "      <td>18.825931</td>\n",
       "      <td>26.838130</td>\n",
       "      <td>68.491793</td>\n",
       "      <td>56.253671</td>\n",
       "      <td>56.953766</td>\n",
       "      <td>56.845700</td>\n",
       "      <td>40.278345</td>\n",
       "      <td>67.425098</td>\n",
       "      <td>34.825321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>31.852434</td>\n",
       "      <td>61.778398</td>\n",
       "      <td>57.840384</td>\n",
       "      <td>54.903516</td>\n",
       "      <td>73.385423</td>\n",
       "      <td>35.859183</td>\n",
       "      <td>67.013429</td>\n",
       "      <td>19.272839</td>\n",
       "      <td>28.340695</td>\n",
       "      <td>67.036948</td>\n",
       "      <td>54.152942</td>\n",
       "      <td>57.643322</td>\n",
       "      <td>57.872572</td>\n",
       "      <td>42.950470</td>\n",
       "      <td>70.896452</td>\n",
       "      <td>32.921381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>65.528129</td>\n",
       "      <td>74.483144</td>\n",
       "      <td>73.039392</td>\n",
       "      <td>89.297779</td>\n",
       "      <td>27.555508</td>\n",
       "      <td>83.162487</td>\n",
       "      <td>43.612903</td>\n",
       "      <td>56.844783</td>\n",
       "      <td>57.897335</td>\n",
       "      <td>64.349501</td>\n",
       "      <td>71.198412</td>\n",
       "      <td>78.154946</td>\n",
       "      <td>48.607991</td>\n",
       "      <td>65.464224</td>\n",
       "      <td>83.840070</td>\n",
       "      <td>60.684671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>64.107987</td>\n",
       "      <td>66.046177</td>\n",
       "      <td>75.274512</td>\n",
       "      <td>90.520823</td>\n",
       "      <td>31.433213</td>\n",
       "      <td>93.542128</td>\n",
       "      <td>50.720566</td>\n",
       "      <td>62.356674</td>\n",
       "      <td>57.320584</td>\n",
       "      <td>64.607780</td>\n",
       "      <td>69.960808</td>\n",
       "      <td>79.909599</td>\n",
       "      <td>49.656041</td>\n",
       "      <td>69.585693</td>\n",
       "      <td>89.394417</td>\n",
       "      <td>63.170028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>31.374927</td>\n",
       "      <td>57.366661</td>\n",
       "      <td>55.983274</td>\n",
       "      <td>80.482129</td>\n",
       "      <td>74.296349</td>\n",
       "      <td>62.243525</td>\n",
       "      <td>77.270144</td>\n",
       "      <td>26.859598</td>\n",
       "      <td>25.892927</td>\n",
       "      <td>64.552009</td>\n",
       "      <td>54.943557</td>\n",
       "      <td>81.575739</td>\n",
       "      <td>70.034335</td>\n",
       "      <td>74.667670</td>\n",
       "      <td>91.284360</td>\n",
       "      <td>34.319828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient  Mean Time  Mean VGFR_left_s1  Mean VGFR_left_s2  \\\n",
       "0        0  60.590759         118.051940          68.692077   \n",
       "1        0  60.590759         111.420777          84.344456   \n",
       "2        0  60.590759         103.878062          84.826031   \n",
       "3        0  60.590759          87.844976          70.259019   \n",
       "4        0  60.590759         102.242404          79.036543   \n",
       "5        0  60.590759          32.261054          62.842370   \n",
       "6        0  60.590759          31.852434          61.778398   \n",
       "7        0  60.590759          65.528129          74.483144   \n",
       "8        0  60.590759          64.107987          66.046177   \n",
       "9        0  60.590759          31.374927          57.366661   \n",
       "\n",
       "   Mean VGFR_left_s3  Mean VGFR_left_s4  Mean VGFR_left_s5  Mean VGFR_left_s6  \\\n",
       "0          48.425916          43.703414          20.648383          94.384729   \n",
       "1          67.783647          44.369387           5.277250          78.684485   \n",
       "2          62.567225          45.874475           8.007434          71.013270   \n",
       "3          86.646486          90.969328          12.027907          92.903315   \n",
       "4          81.320073          98.200889          13.159388          92.903569   \n",
       "5          59.733458          53.399572          75.651052          32.047481   \n",
       "6          57.840384          54.903516          73.385423          35.859183   \n",
       "7          73.039392          89.297779          27.555508          83.162487   \n",
       "8          75.274512          90.520823          31.433213          93.542128   \n",
       "9          55.983274          80.482129          74.296349          62.243525   \n",
       "\n",
       "   Mean VGFR_left_s7  Mean VGFR_left_s8  Mean VGFR_right_s1  \\\n",
       "0          93.851677          32.885407          100.967355   \n",
       "1          28.449642          20.862919           94.473515   \n",
       "2          30.271631          22.709544           87.211491   \n",
       "3         109.522665          50.506421          115.009085   \n",
       "4         101.985595          47.110582          111.480607   \n",
       "5          63.601250          18.825931           26.838130   \n",
       "6          67.013429          19.272839           28.340695   \n",
       "7          43.612903          56.844783           57.897335   \n",
       "8          50.720566          62.356674           57.320584   \n",
       "9          77.270144          26.859598           25.892927   \n",
       "\n",
       "   Mean VGFR_right_s2  Mean VGFR_right_s3  Mean VGFR_right_s4  \\\n",
       "0           61.528515           51.848497           70.042432   \n",
       "1           62.610805           59.430945           47.720293   \n",
       "2           70.739540           53.453065           55.558587   \n",
       "3           82.005218           67.853397          100.646351   \n",
       "4          101.130204           54.169980          107.104625   \n",
       "5           68.491793           56.253671           56.953766   \n",
       "6           67.036948           54.152942           57.643322   \n",
       "7           64.349501           71.198412           78.154946   \n",
       "8           64.607780           69.960808           79.909599   \n",
       "9           64.552009           54.943557           81.575739   \n",
       "\n",
       "   Mean VGFR_right_s5  Mean VGFR_right_s6  Mean VGFR_right_s7  \\\n",
       "0           16.359854          104.850143          114.499416   \n",
       "1            6.488666           90.836907           55.465798   \n",
       "2            9.545464           83.647538           56.830314   \n",
       "3           28.439566           64.241570           91.184290   \n",
       "4           23.475233           78.174462           87.135885   \n",
       "5           56.845700           40.278345           67.425098   \n",
       "6           57.872572           42.950470           70.896452   \n",
       "7           48.607991           65.464224           83.840070   \n",
       "8           49.656041           69.585693           89.394417   \n",
       "9           70.034335           74.667670           91.284360   \n",
       "\n",
       "   Mean VGFR_right_s8  \n",
       "0           43.202804  \n",
       "1           30.942615  \n",
       "2           32.571147  \n",
       "3           41.847457  \n",
       "4           39.752083  \n",
       "5           34.825321  \n",
       "6           32.921381  \n",
       "7           60.684671  \n",
       "8           63.170028  \n",
       "9           34.319828  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Mean Time</th>\n",
       "      <th>Mean VGFR_left_s1</th>\n",
       "      <th>Mean VGFR_left_s2</th>\n",
       "      <th>Mean VGFR_left_s3</th>\n",
       "      <th>Mean VGFR_left_s4</th>\n",
       "      <th>Mean VGFR_left_s5</th>\n",
       "      <th>Mean VGFR_left_s6</th>\n",
       "      <th>Mean VGFR_left_s7</th>\n",
       "      <th>Mean VGFR_left_s8</th>\n",
       "      <th>Mean VGFR_right_s1</th>\n",
       "      <th>Mean VGFR_right_s2</th>\n",
       "      <th>Mean VGFR_right_s3</th>\n",
       "      <th>Mean VGFR_right_s4</th>\n",
       "      <th>Mean VGFR_right_s5</th>\n",
       "      <th>Mean VGFR_right_s6</th>\n",
       "      <th>Mean VGFR_right_s7</th>\n",
       "      <th>Mean VGFR_right_s8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>9.800675</td>\n",
       "      <td>43.605596</td>\n",
       "      <td>50.329711</td>\n",
       "      <td>110.029946</td>\n",
       "      <td>51.060606</td>\n",
       "      <td>76.749191</td>\n",
       "      <td>70.068911</td>\n",
       "      <td>30.088649</td>\n",
       "      <td>29.766029</td>\n",
       "      <td>64.698282</td>\n",
       "      <td>106.625438</td>\n",
       "      <td>87.690197</td>\n",
       "      <td>60.692468</td>\n",
       "      <td>51.125890</td>\n",
       "      <td>74.689501</td>\n",
       "      <td>27.167440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>33.979552</td>\n",
       "      <td>83.758691</td>\n",
       "      <td>73.700971</td>\n",
       "      <td>84.527448</td>\n",
       "      <td>29.641460</td>\n",
       "      <td>68.581723</td>\n",
       "      <td>70.120434</td>\n",
       "      <td>36.247832</td>\n",
       "      <td>46.984215</td>\n",
       "      <td>79.226297</td>\n",
       "      <td>95.497211</td>\n",
       "      <td>82.120873</td>\n",
       "      <td>43.006160</td>\n",
       "      <td>51.329814</td>\n",
       "      <td>64.724906</td>\n",
       "      <td>29.853635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>37.892567</td>\n",
       "      <td>98.744053</td>\n",
       "      <td>82.766730</td>\n",
       "      <td>51.206498</td>\n",
       "      <td>41.187493</td>\n",
       "      <td>45.656427</td>\n",
       "      <td>93.033657</td>\n",
       "      <td>21.079043</td>\n",
       "      <td>44.505267</td>\n",
       "      <td>81.129067</td>\n",
       "      <td>77.618743</td>\n",
       "      <td>61.580320</td>\n",
       "      <td>57.299960</td>\n",
       "      <td>39.014807</td>\n",
       "      <td>82.577539</td>\n",
       "      <td>18.266881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>23.908252</td>\n",
       "      <td>52.373861</td>\n",
       "      <td>56.935385</td>\n",
       "      <td>44.716135</td>\n",
       "      <td>43.170824</td>\n",
       "      <td>59.079286</td>\n",
       "      <td>74.753133</td>\n",
       "      <td>28.271298</td>\n",
       "      <td>32.821856</td>\n",
       "      <td>46.398296</td>\n",
       "      <td>71.447859</td>\n",
       "      <td>61.338707</td>\n",
       "      <td>56.951206</td>\n",
       "      <td>48.148156</td>\n",
       "      <td>64.314435</td>\n",
       "      <td>23.895226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>58.680616</td>\n",
       "      <td>66.053720</td>\n",
       "      <td>34.236424</td>\n",
       "      <td>71.075078</td>\n",
       "      <td>5.636905</td>\n",
       "      <td>106.108317</td>\n",
       "      <td>78.164014</td>\n",
       "      <td>37.476023</td>\n",
       "      <td>81.413916</td>\n",
       "      <td>75.818131</td>\n",
       "      <td>42.522852</td>\n",
       "      <td>36.769738</td>\n",
       "      <td>4.842805</td>\n",
       "      <td>72.887046</td>\n",
       "      <td>129.364248</td>\n",
       "      <td>28.629338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>16.966606</td>\n",
       "      <td>50.672211</td>\n",
       "      <td>22.875271</td>\n",
       "      <td>58.176293</td>\n",
       "      <td>35.249318</td>\n",
       "      <td>47.965810</td>\n",
       "      <td>105.517151</td>\n",
       "      <td>21.397578</td>\n",
       "      <td>43.486546</td>\n",
       "      <td>68.550379</td>\n",
       "      <td>57.711103</td>\n",
       "      <td>31.341277</td>\n",
       "      <td>28.224795</td>\n",
       "      <td>46.095056</td>\n",
       "      <td>99.072628</td>\n",
       "      <td>27.853864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>32.446215</td>\n",
       "      <td>37.921397</td>\n",
       "      <td>38.830944</td>\n",
       "      <td>30.461386</td>\n",
       "      <td>30.053819</td>\n",
       "      <td>48.487733</td>\n",
       "      <td>85.376085</td>\n",
       "      <td>41.489843</td>\n",
       "      <td>28.130508</td>\n",
       "      <td>44.421110</td>\n",
       "      <td>33.491959</td>\n",
       "      <td>59.292469</td>\n",
       "      <td>24.099096</td>\n",
       "      <td>64.898430</td>\n",
       "      <td>53.896287</td>\n",
       "      <td>38.616291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>32.399393</td>\n",
       "      <td>59.714251</td>\n",
       "      <td>59.493670</td>\n",
       "      <td>58.755967</td>\n",
       "      <td>34.800975</td>\n",
       "      <td>24.376583</td>\n",
       "      <td>43.363692</td>\n",
       "      <td>13.333610</td>\n",
       "      <td>32.074540</td>\n",
       "      <td>67.940059</td>\n",
       "      <td>66.667779</td>\n",
       "      <td>72.224450</td>\n",
       "      <td>25.755132</td>\n",
       "      <td>26.385748</td>\n",
       "      <td>25.225729</td>\n",
       "      <td>14.025654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>95.909034</td>\n",
       "      <td>103.131454</td>\n",
       "      <td>81.760391</td>\n",
       "      <td>55.547186</td>\n",
       "      <td>49.690852</td>\n",
       "      <td>39.367900</td>\n",
       "      <td>59.634016</td>\n",
       "      <td>16.972851</td>\n",
       "      <td>65.252984</td>\n",
       "      <td>89.831303</td>\n",
       "      <td>61.035059</td>\n",
       "      <td>73.125927</td>\n",
       "      <td>72.106770</td>\n",
       "      <td>44.736786</td>\n",
       "      <td>80.466607</td>\n",
       "      <td>23.287739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1</td>\n",
       "      <td>60.590759</td>\n",
       "      <td>89.616250</td>\n",
       "      <td>47.806937</td>\n",
       "      <td>69.467224</td>\n",
       "      <td>43.235619</td>\n",
       "      <td>16.774083</td>\n",
       "      <td>67.842241</td>\n",
       "      <td>123.661468</td>\n",
       "      <td>36.907632</td>\n",
       "      <td>55.456675</td>\n",
       "      <td>31.466082</td>\n",
       "      <td>52.953372</td>\n",
       "      <td>37.505071</td>\n",
       "      <td>18.529181</td>\n",
       "      <td>71.203795</td>\n",
       "      <td>118.300425</td>\n",
       "      <td>30.450393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient  Mean Time  Mean VGFR_left_s1  Mean VGFR_left_s2  \\\n",
       "296        1  60.590759           9.800675          43.605596   \n",
       "297        1  60.590759          33.979552          83.758691   \n",
       "298        1  60.590759          37.892567          98.744053   \n",
       "299        1  60.590759          23.908252          52.373861   \n",
       "300        1  60.590759          58.680616          66.053720   \n",
       "301        1  60.590759          16.966606          50.672211   \n",
       "302        1  60.590759          32.446215          37.921397   \n",
       "303        1  60.590759          32.399393          59.714251   \n",
       "304        1  60.590759          95.909034         103.131454   \n",
       "305        1  60.590759          89.616250          47.806937   \n",
       "\n",
       "     Mean VGFR_left_s3  Mean VGFR_left_s4  Mean VGFR_left_s5  \\\n",
       "296          50.329711         110.029946          51.060606   \n",
       "297          73.700971          84.527448          29.641460   \n",
       "298          82.766730          51.206498          41.187493   \n",
       "299          56.935385          44.716135          43.170824   \n",
       "300          34.236424          71.075078           5.636905   \n",
       "301          22.875271          58.176293          35.249318   \n",
       "302          38.830944          30.461386          30.053819   \n",
       "303          59.493670          58.755967          34.800975   \n",
       "304          81.760391          55.547186          49.690852   \n",
       "305          69.467224          43.235619          16.774083   \n",
       "\n",
       "     Mean VGFR_left_s6  Mean VGFR_left_s7  Mean VGFR_left_s8  \\\n",
       "296          76.749191          70.068911          30.088649   \n",
       "297          68.581723          70.120434          36.247832   \n",
       "298          45.656427          93.033657          21.079043   \n",
       "299          59.079286          74.753133          28.271298   \n",
       "300         106.108317          78.164014          37.476023   \n",
       "301          47.965810         105.517151          21.397578   \n",
       "302          48.487733          85.376085          41.489843   \n",
       "303          24.376583          43.363692          13.333610   \n",
       "304          39.367900          59.634016          16.972851   \n",
       "305          67.842241         123.661468          36.907632   \n",
       "\n",
       "     Mean VGFR_right_s1  Mean VGFR_right_s2  Mean VGFR_right_s3  \\\n",
       "296           29.766029           64.698282          106.625438   \n",
       "297           46.984215           79.226297           95.497211   \n",
       "298           44.505267           81.129067           77.618743   \n",
       "299           32.821856           46.398296           71.447859   \n",
       "300           81.413916           75.818131           42.522852   \n",
       "301           43.486546           68.550379           57.711103   \n",
       "302           28.130508           44.421110           33.491959   \n",
       "303           32.074540           67.940059           66.667779   \n",
       "304           65.252984           89.831303           61.035059   \n",
       "305           55.456675           31.466082           52.953372   \n",
       "\n",
       "     Mean VGFR_right_s4  Mean VGFR_right_s5  Mean VGFR_right_s6  \\\n",
       "296           87.690197           60.692468           51.125890   \n",
       "297           82.120873           43.006160           51.329814   \n",
       "298           61.580320           57.299960           39.014807   \n",
       "299           61.338707           56.951206           48.148156   \n",
       "300           36.769738            4.842805           72.887046   \n",
       "301           31.341277           28.224795           46.095056   \n",
       "302           59.292469           24.099096           64.898430   \n",
       "303           72.224450           25.755132           26.385748   \n",
       "304           73.125927           72.106770           44.736786   \n",
       "305           37.505071           18.529181           71.203795   \n",
       "\n",
       "     Mean VGFR_right_s7  Mean VGFR_right_s8  \n",
       "296           74.689501           27.167440  \n",
       "297           64.724906           29.853635  \n",
       "298           82.577539           18.266881  \n",
       "299           64.314435           23.895226  \n",
       "300          129.364248           28.629338  \n",
       "301           99.072628           27.853864  \n",
       "302           53.896287           38.616291  \n",
       "303           25.225729           14.025654  \n",
       "304           80.466607           23.287739  \n",
       "305          118.300425           30.450393  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gabor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor(x, sigma):\n",
    "    omega = 2*np.pi*60.59\n",
    "    parameter_1 = 2*np.pi*sigma\n",
    "    expression_1 = 1/(math.sqrt(parameter_1))\n",
    "    parameter_2 = -int((x**2/2*sigma**2))\n",
    "    if parameter_2 < 0:\n",
    "        length = len(str(parameter_2)) - 2\n",
    "    else:\n",
    "        length = len(str(parameter_2)) - 1\n",
    "    parameter_2 = int(parameter_2/int(str(1)+str(0)*length))\n",
    "    expression_2 = math.exp(parameter_2)\n",
    "    parameter_3 = 2*np.pi*omega*x\n",
    "    if x%2 == 0:\n",
    "        expression_3 = math.cos(parameter_3)\n",
    "    else:\n",
    "        expression_3 = math.sin(parameter_3)\n",
    "    gaborbor_filter = expression_1*expression_2*expression_3\n",
    "    return round(gaborbor_filter,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_Mean_VGFR_left_s1 = []\n",
    "gabor_Mean_VGFR_left_s2 = []\n",
    "gabor_Mean_VGFR_left_s3 = []\n",
    "gabor_Mean_VGFR_left_s4 = []\n",
    "gabor_Mean_VGFR_left_s5 = []\n",
    "gabor_Mean_VGFR_left_s6 = []\n",
    "gabor_Mean_VGFR_left_s7 = []\n",
    "gabor_Mean_VGFR_left_s8 = []\n",
    "gabor_Mean_VGFR_right_s1 = []\n",
    "gabor_Mean_VGFR_right_s2 = []\n",
    "gabor_Mean_VGFR_right_s3 = []\n",
    "gabor_Mean_VGFR_right_s4 = []\n",
    "gabor_Mean_VGFR_right_s5 = []\n",
    "gabor_Mean_VGFR_right_s6 = []\n",
    "gabor_Mean_VGFR_right_s7 = []\n",
    "gabor_Mean_VGFR_right_s8 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 306/306 [00:00<00:00, 1488.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(306)):\n",
    "    for j in range(1,4):\n",
    "        gabor_Mean_VGFR_left_s1.append(gabor(mean_VGRF_left1[i], j))\n",
    "        gabor_Mean_VGFR_left_s2.append(gabor(mean_VGRF_left2[i], j))\n",
    "        gabor_Mean_VGFR_left_s3.append(gabor(mean_VGRF_left3[i], j))\n",
    "        gabor_Mean_VGFR_left_s4.append(gabor(mean_VGRF_left4[i], j))\n",
    "        gabor_Mean_VGFR_left_s5.append(gabor(mean_VGRF_left5[i], j))\n",
    "        gabor_Mean_VGFR_left_s6.append(gabor(mean_VGRF_left6[i], j))\n",
    "        gabor_Mean_VGFR_left_s7.append(gabor(mean_VGRF_left7[i], j))\n",
    "        gabor_Mean_VGFR_left_s8.append(gabor(mean_VGRF_left8[i], j))\n",
    "        gabor_Mean_VGFR_right_s1.append(gabor(mean_VGRF_right1[i], j))\n",
    "        gabor_Mean_VGFR_right_s2.append(gabor(mean_VGRF_right2[i], j))\n",
    "        gabor_Mean_VGFR_right_s3.append(gabor(mean_VGRF_right3[i], j))\n",
    "        gabor_Mean_VGFR_right_s4.append(gabor(mean_VGRF_right4[i], j))\n",
    "        gabor_Mean_VGFR_right_s5.append(gabor(mean_VGRF_right5[i], j))\n",
    "        gabor_Mean_VGFR_right_s6.append(gabor(mean_VGRF_right6[i], j))\n",
    "        gabor_Mean_VGFR_right_s7.append(gabor(mean_VGRF_right7[i], j))\n",
    "        gabor_Mean_VGFR_right_s8.append(gabor(mean_VGRF_right8[i], j))\n",
    "patient_ = []\n",
    "for i in range(len(patient)):\n",
    "    for j in range(1,4):\n",
    "        patient_.append(patient[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset After Applying Gabor Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_new_dataframe = {\n",
    "    \"Patient\" : patient_,\n",
    "    \" Gabor Mean_VGFR_left_s1\" :  gabor_Mean_VGFR_left_s1,\n",
    "    \" Gabor Mean_VGFR_left_s2\" :  gabor_Mean_VGFR_left_s2,\n",
    "    \" Gabor Mean_VGFR_left_s3\" :  gabor_Mean_VGFR_left_s3,\n",
    "    \" Gabor Mean_VGFR_left_s4\" :  gabor_Mean_VGFR_left_s4,\n",
    "    \" Gabor Mean_VGFR_left_s5\" :  gabor_Mean_VGFR_left_s5,\n",
    "    \" Gabor Mean_VGFR_left_s6\" :  gabor_Mean_VGFR_left_s6,\n",
    "    \" Gabor Mean_VGFR_left_s7\" :  gabor_Mean_VGFR_left_s7,\n",
    "    \" Gabor Mean_VGFR_left_s8\" :  gabor_Mean_VGFR_left_s8,\n",
    "    \" Gabor Mean_VGFR_right_s1\" : gabor_Mean_VGFR_right_s1,\n",
    "    \" Gabor Mean_VGFR_right_s2\" : gabor_Mean_VGFR_right_s2,\n",
    "    \" Gabor Mean_VGFR_right_s3\" : gabor_Mean_VGFR_right_s3,\n",
    "    \" Gabor Mean_VGFR_right_s4\" : gabor_Mean_VGFR_right_s4,\n",
    "    \" Gabor Mean_VGFR_right_s5\" : gabor_Mean_VGFR_right_s5,\n",
    "    \" Gabor Mean_VGFR_right_s6\" : gabor_Mean_VGFR_right_s6,\n",
    "    \" Gabor Mean_VGFR_right_s7\" : gabor_Mean_VGFR_right_s7,\n",
    "    \" Gabor Mean_VGFR_right_s8\" : gabor_Mean_VGFR_right_s8,}\n",
    "gabor_filter_df = pd.DataFrame(dict_of_new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Gabor Mean_VGFR_left_s1</th>\n",
       "      <th>Gabor Mean_VGFR_left_s2</th>\n",
       "      <th>Gabor Mean_VGFR_left_s3</th>\n",
       "      <th>Gabor Mean_VGFR_left_s4</th>\n",
       "      <th>Gabor Mean_VGFR_left_s5</th>\n",
       "      <th>Gabor Mean_VGFR_left_s6</th>\n",
       "      <th>Gabor Mean_VGFR_left_s7</th>\n",
       "      <th>Gabor Mean_VGFR_left_s8</th>\n",
       "      <th>Gabor Mean_VGFR_right_s1</th>\n",
       "      <th>Gabor Mean_VGFR_right_s2</th>\n",
       "      <th>Gabor Mean_VGFR_right_s3</th>\n",
       "      <th>Gabor Mean_VGFR_right_s4</th>\n",
       "      <th>Gabor Mean_VGFR_right_s5</th>\n",
       "      <th>Gabor Mean_VGFR_right_s6</th>\n",
       "      <th>Gabor Mean_VGFR_right_s7</th>\n",
       "      <th>Gabor Mean_VGFR_right_s8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>-0.123391</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.051097</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>-0.140952</td>\n",
       "      <td>-0.106650</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.127212</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.004344</td>\n",
       "      <td>-0.013028</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.089069</td>\n",
       "      <td>0.019410</td>\n",
       "      <td>0.020486</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-0.001381</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.038096</td>\n",
       "      <td>-0.037555</td>\n",
       "      <td>0.013930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.009643</td>\n",
       "      <td>-0.071240</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.080192</td>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.009842</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>-0.081379</td>\n",
       "      <td>-0.061575</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>-0.001527</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000917</td>\n",
       "      <td>-0.019451</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>-0.007233</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>-0.132486</td>\n",
       "      <td>0.146725</td>\n",
       "      <td>0.027069</td>\n",
       "      <td>0.053233</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>-0.145527</td>\n",
       "      <td>-0.006980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.035419</td>\n",
       "      <td>-0.101626</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.026852</td>\n",
       "      <td>-0.102731</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.062538</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>-0.000693</td>\n",
       "      <td>-0.099130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient   Gabor Mean_VGFR_left_s1   Gabor Mean_VGFR_left_s2  \\\n",
       "0        0                  0.000838                 -0.016702   \n",
       "1        0                  0.032341                 -0.000011   \n",
       "2        0                  0.000484                 -0.009643   \n",
       "3        0                 -0.000917                 -0.019451   \n",
       "4        0                 -0.035419                 -0.101626   \n",
       "\n",
       "    Gabor Mean_VGFR_left_s3   Gabor Mean_VGFR_left_s4  \\\n",
       "0                 -0.123391                 -0.000046   \n",
       "1                 -0.004344                 -0.013028   \n",
       "2                 -0.071240                 -0.000072   \n",
       "3                  0.034965                  0.000041   \n",
       "4                  0.000023                  0.011586   \n",
       "\n",
       "    Gabor Mean_VGFR_left_s5   Gabor Mean_VGFR_left_s6  \\\n",
       "0                 -0.051097                  0.004158   \n",
       "1                 -0.000090                  0.059058   \n",
       "2                 -0.080192                  0.002401   \n",
       "3                  0.035955                  0.005139   \n",
       "4                  0.000466                  0.026852   \n",
       "\n",
       "    Gabor Mean_VGFR_left_s7   Gabor Mean_VGFR_left_s8  \\\n",
       "0                  0.006271                  0.001367   \n",
       "1                  0.089069                  0.019410   \n",
       "2                  0.009842                  0.002145   \n",
       "3                 -0.007233                  0.008249   \n",
       "4                 -0.102731                  0.000014   \n",
       "\n",
       "    Gabor Mean_VGFR_right_s1   Gabor Mean_VGFR_right_s2  \\\n",
       "0                   0.001442                  -0.140952   \n",
       "1                   0.020486                  -0.000247   \n",
       "2                   0.002264                  -0.081379   \n",
       "3                  -0.004403                  -0.132486   \n",
       "4                  -0.062538                  -0.000232   \n",
       "\n",
       "    Gabor Mean_VGFR_right_s3   Gabor Mean_VGFR_right_s4  \\\n",
       "0                  -0.106650                   0.009316   \n",
       "1                  -0.001381                   0.000006   \n",
       "2                  -0.061575                   0.005378   \n",
       "3                   0.146725                   0.027069   \n",
       "4                   0.000257                   0.000953   \n",
       "\n",
       "    Gabor Mean_VGFR_right_s5   Gabor Mean_VGFR_right_s6  \\\n",
       "0                   0.127212                   0.002682   \n",
       "1                   0.001648                   0.038096   \n",
       "2                   0.073446                   0.004210   \n",
       "3                   0.053233                   0.002397   \n",
       "4                   0.000093                   0.034037   \n",
       "\n",
       "    Gabor Mean_VGFR_right_s7   Gabor Mean_VGFR_right_s8  \n",
       "0                  -0.000973                   0.000049  \n",
       "1                  -0.037555                   0.013930  \n",
       "2                  -0.001527                   0.000077  \n",
       "3                  -0.145527                  -0.006980  \n",
       "4                  -0.000693                  -0.099130  "
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabor_filter_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabor_total_left_leg = []\n",
    "gabor_total_right_leg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(918):\n",
    "    gabor_total_left_leg.append((gabor_Mean_VGFR_left_s1[i] + gabor_Mean_VGFR_left_s2[i] + gabor_Mean_VGFR_left_s3[i] + \n",
    "                                gabor_Mean_VGFR_left_s4[i] + gabor_Mean_VGFR_left_s5[i] + gabor_Mean_VGFR_left_s6[i] + \n",
    "                                gabor_Mean_VGFR_left_s7[i] + gabor_Mean_VGFR_left_s8[i])/8)\n",
    "    gabor_total_right_leg.append((gabor_Mean_VGFR_right_s1[i] + gabor_Mean_VGFR_right_s2[i] + gabor_Mean_VGFR_right_s3[i] + \n",
    "                                 gabor_Mean_VGFR_right_s4[i] + gabor_Mean_VGFR_right_s5[i] + gabor_Mean_VGFR_right_s6[i]\n",
    "                                 + gabor_Mean_VGFR_right_s7[i] + gabor_Mean_VGFR_right_s8[i])/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_new_dataframe = {\n",
    "    \"Patient\" : patient_,\n",
    "    \"Gabor Total Left\" : gabor_total_left_leg, \"Gabor Total Right\" : gabor_total_right_leg}\n",
    "gabor_filter_df = pd.DataFrame(dict_of_new_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Gabor Total Left</th>\n",
       "      <th>Gabor Total Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.022325</td>\n",
       "      <td>-0.013484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.018284</td>\n",
       "      <td>-0.007388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>-0.007496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.025104</td>\n",
       "      <td>-0.015907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient  Gabor Total Left  Gabor Total Right\n",
       "0        0         -0.022325          -0.013484\n",
       "1        0          0.022801           0.004373\n",
       "2        0         -0.018284          -0.007388\n",
       "3        0          0.007093          -0.007496\n",
       "4        0         -0.025104          -0.015907"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabor_filter_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>Gabor Total Left</th>\n",
       "      <th>Gabor Total Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>-0.028469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005657</td>\n",
       "      <td>-0.021124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.008024</td>\n",
       "      <td>0.046109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.020644</td>\n",
       "      <td>0.022750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>0.026651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Patient  Gabor Total Left  Gabor Total Right\n",
       "913        1          0.011528          -0.028469\n",
       "914        1         -0.005657          -0.021124\n",
       "915        1         -0.008024           0.046109\n",
       "916        1         -0.020644           0.022750\n",
       "917        1         -0.005587           0.026651"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabor_filter_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = []\n",
    "standard_deviation_of_gabor_filter = []\n",
    "entropy_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 918/918 [00:00<00:00, 3671.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 918/918 [00:00<00:00, 16103.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(gabor_total_left_leg))):\n",
    "    mean.append(gabor_total_left_leg[i] + gabor_total_right_leg[i]/2),\n",
    "    standard_deviation_of_gabor_filter.append(statistics.stdev([gabor_total_left_leg[i], gabor_total_right_leg[i]]))\n",
    "for i in tqdm(range(len(gabor_total_left_leg))):\n",
    "    entropy_.append(entropy([abs(gabor_total_left_leg[i]), abs(gabor_total_right_leg[i])]))\n",
    "skew_ = gabor_filter_df.skew(axis=1, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_gabor_dataset = {\"Mean\" : mean, \"Std\" : standard_deviation_of_gabor_filter, \"Skew\" : skew_, \n",
    "                      \"Entropy\" : entropy_, \"patient\" : patient_}\n",
    "gabor_dataset = pd.DataFrame(dict_gabor_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.029067</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.607755</td>\n",
       "      <td>0.662352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024987</td>\n",
       "      <td>0.013030</td>\n",
       "      <td>1.481078</td>\n",
       "      <td>0.441199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021979</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>-0.562810</td>\n",
       "      <td>0.600158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003345</td>\n",
       "      <td>0.010317</td>\n",
       "      <td>-0.082826</td>\n",
       "      <td>0.692766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.033058</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.767777</td>\n",
       "      <td>0.667782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006035</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>-0.245772</td>\n",
       "      <td>0.648141</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.049676</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>-1.671666</td>\n",
       "      <td>0.691841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.029299</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>-0.385349</td>\n",
       "      <td>0.653978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>-1.034282</td>\n",
       "      <td>0.675912</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.018742</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>1.418337</td>\n",
       "      <td>0.686013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean       Std      Skew   Entropy  patient\n",
       "0 -0.029067  0.006252  0.607755  0.662352        0\n",
       "1  0.024987  0.013030  1.481078  0.441199        0\n",
       "2 -0.021979  0.007705 -0.562810  0.600158        0\n",
       "3  0.003345  0.010317 -0.082826  0.692766        0\n",
       "4 -0.033058  0.006504  0.767777  0.667782        0\n",
       "5  0.006035  0.001541 -0.245772  0.648141        0\n",
       "6  0.049676  0.002353 -1.671666  0.691841        0\n",
       "7  0.029299  0.007029 -0.385349  0.653978        0\n",
       "8  0.020796  0.003868 -1.034282  0.675912        0\n",
       "9 -0.018742  0.002028  1.418337  0.686013        0"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabor_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>1.731425</td>\n",
       "      <td>0.108310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>0.044815</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>1.714877</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.016506</td>\n",
       "      <td>1.728884</td>\n",
       "      <td>0.667218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0.026095</td>\n",
       "      <td>0.021607</td>\n",
       "      <td>1.726461</td>\n",
       "      <td>0.319213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>-0.013237</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>1.732009</td>\n",
       "      <td>0.680078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>-0.002706</td>\n",
       "      <td>0.028282</td>\n",
       "      <td>1.722871</td>\n",
       "      <td>0.600558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>-0.016219</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>1.730689</td>\n",
       "      <td>0.515571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.038278</td>\n",
       "      <td>1.714307</td>\n",
       "      <td>0.419617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>-0.009269</td>\n",
       "      <td>0.030684</td>\n",
       "      <td>1.721042</td>\n",
       "      <td>0.691969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>0.007738</td>\n",
       "      <td>0.022795</td>\n",
       "      <td>1.725853</td>\n",
       "      <td>0.461091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Mean       Std      Skew   Entropy  patient\n",
       "908  0.009948  0.007282  1.731425  0.108310        1\n",
       "909  0.044815  0.037580  1.714877  0.334878        1\n",
       "910  0.001866  0.016506  1.728884  0.667218        1\n",
       "911  0.026095  0.021607  1.726461  0.319213        1\n",
       "912 -0.013237  0.001911  1.732009  0.680078        1\n",
       "913 -0.002706  0.028282  1.722871  0.600558        1\n",
       "914 -0.016219  0.010937  1.730689  0.515571        1\n",
       "915  0.015031  0.038278  1.714307  0.419617        1\n",
       "916 -0.009269  0.030684  1.721042  0.691969        1\n",
       "917  0.007738  0.022795  1.725853  0.461091        1"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gabor_dataset.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = gabor_dataset[['Mean', 'Std', 'Skew', 'Entropy']]\n",
    "y = gabor_dataset['patient']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 15)\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_y_pred = svclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.91304347826086%\n",
      "Precision: 98.51851851851852%\n",
      "Recall: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, svm_y_pred) * 100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, svm_y_pred) * 100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, svm_y_pred) * 100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 49   2]\n",
      " [  0 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        51\n",
      "           1       0.99      1.00      0.99       133\n",
      "\n",
      "    accuracy                           0.99       184\n",
      "   macro avg       0.99      0.98      0.99       184\n",
      "weighted avg       0.99      0.99      0.99       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,svm_y_pred))\n",
    "print(classification_report(y_test,svm_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  96.07843137254902%\n",
      "Sensitivity:  100.0%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, svm_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 33)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "logreg_y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.82608695652173%\n",
      "Precision: 97.16312056737588%\n",
      "Recall: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, logreg_y_pred)*100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, logreg_y_pred)*100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, logreg_y_pred)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43   4]\n",
      " [  0 137]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.96        47\n",
      "           1       0.97      1.00      0.99       137\n",
      "\n",
      "    accuracy                           0.98       184\n",
      "   macro avg       0.99      0.96      0.97       184\n",
      "weighted avg       0.98      0.98      0.98       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,logreg_y_pred))\n",
    "print(classification_report(y_test,logreg_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  91.48936170212765%\n",
      "Sensitivity:  100.0%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, logreg_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 72)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(abs(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbs_y_pred = nbs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.80434782608695%\n",
      "Precision: 78.80434782608695%\n",
      "Recall: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, nbs_y_pred)*100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, nbs_y_pred)*100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, nbs_y_pred)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  39]\n",
      " [  0 145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        39\n",
      "           1       0.79      1.00      0.88       145\n",
      "\n",
      "    accuracy                           0.79       184\n",
      "   macro avg       0.39      0.50      0.44       184\n",
      "weighted avg       0.62      0.79      0.69       184\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Python\\include\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,nbs_y_pred))\n",
    "print(classification_report(y_test,nbs_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.0%\n",
      "Sensitivity:  100.0%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, nbs_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_y_pred = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.91304347826086%\n",
      "Precision: 98.54014598540147%\n",
      "Recall: 100.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, sgd_y_pred)*100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, sgd_y_pred)*100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, sgd_y_pred)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 47   2]\n",
      " [  0 135]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        49\n",
      "           1       0.99      1.00      0.99       135\n",
      "\n",
      "    accuracy                           0.99       184\n",
      "   macro avg       0.99      0.98      0.99       184\n",
      "weighted avg       0.99      0.99      0.99       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,sgd_y_pred))\n",
    "print(classification_report(y_test,sgd_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  95.91836734693877%\n",
      "Sensitivity:  100.0%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, sgd_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train1, y_test1 = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.36956521739131%\n",
      "Precision: 99.25373134328358%\n",
      "Recall: 98.51851851851852%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, knn_y_pred)*100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, knn_y_pred)*100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, knn_y_pred)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48   1]\n",
      " [  2 133]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        49\n",
      "           1       0.99      0.99      0.99       135\n",
      "\n",
      "    accuracy                           0.98       184\n",
      "   macro avg       0.98      0.98      0.98       184\n",
      "weighted avg       0.98      0.98      0.98       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,knn_y_pred))\n",
    "print(classification_report(y_test,knn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  97.95918367346938%\n",
      "Sensitivity:  98.51851851851852%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, knn_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=20)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train1, y_test1 = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(max_depth=20, min_samples_leaf=1, max_features= None)\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_y_pred = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.82608695652173%\n",
      "Precision: 99.24812030075188%\n",
      "Recall: 97.77777777777777%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, dtree_y_pred)*100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, dtree_y_pred)*100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, dtree_y_pred)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48   1]\n",
      " [  3 132]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96        49\n",
      "           1       0.99      0.98      0.99       135\n",
      "\n",
      "    accuracy                           0.98       184\n",
      "   macro avg       0.97      0.98      0.97       184\n",
      "weighted avg       0.98      0.98      0.98       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,dtree_y_pred))\n",
    "print(classification_report(y_test,dtree_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  97.95918367346938%\n",
      "Sensitivity:  97.77777777777777%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, dtree_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=None, min_samples_leaf=100, n_jobs=1,\n",
       "                       oob_score=True)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train1, y_test1 = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfm = RandomForestClassifier(n_estimators=100, oob_score=True, n_jobs=1, max_features=None, min_samples_leaf=100)\n",
    "rfm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_y_pred = rfm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.91304347826086%\n",
      "Precision: 99.25925925925925%\n",
      "Recall: 99.25925925925925%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",str(metrics.accuracy_score(y_test, rfm_y_pred)*100)+\"%\")\n",
    "print(\"Precision:\",str(metrics.precision_score(y_test, rfm_y_pred)*100)+\"%\")\n",
    "print(\"Recall:\",str(metrics.recall_score(y_test, rfm_y_pred)*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 48   1]\n",
      " [  1 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        49\n",
      "           1       0.99      0.99      0.99       135\n",
      "\n",
      "    accuracy                           0.99       184\n",
      "   macro avg       0.99      0.99      0.99       184\n",
      "weighted avg       0.99      0.99      0.99       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,rfm_y_pred))\n",
    "print(classification_report(y_test,rfm_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  97.95918367346938%\n",
      "Sensitivity:  99.25925925925925%\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, rfm_y_pred).ravel()\n",
    "specificity = tn / float(tn+fp)\n",
    "sensitivity = (tp / float(tp + fn))\n",
    "print (\"Specificity: \",str(specificity*100)+\"%\")\n",
    "print (\"Sensitivity: \",str(sensitivity*100)+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(16)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=4, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "147/147 [==============================] - 2s 3ms/step - loss: 1.5827 - accuracy: 0.8674\n",
      "Epoch 2/150\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.4692 - accuracy: 0.8878\n",
      "Epoch 3/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 1.4227 - accuracy: 0.8931\n",
      "Epoch 4/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.8999\n",
      "Epoch 5/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.8010 - accuracy: 0.9242\n",
      "Epoch 6/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.9311\n",
      "Epoch 7/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.9365\n",
      "Epoch 8/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.9524\n",
      "Epoch 9/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.9411\n",
      "Epoch 10/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.9339\n",
      "Epoch 11/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.8226 - accuracy: 0.9198\n",
      "Epoch 12/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6013 - accuracy: 0.9261\n",
      "Epoch 13/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.6496 - accuracy: 0.9292\n",
      "Epoch 14/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.9447\n",
      "Epoch 15/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.9301\n",
      "Epoch 16/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.8181 - accuracy: 0.9154\n",
      "Epoch 17/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7384 - accuracy: 0.9112\n",
      "Epoch 18/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.9216\n",
      "Epoch 19/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.9362\n",
      "Epoch 20/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.9273\n",
      "Epoch 21/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.9269\n",
      "Epoch 22/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.9304\n",
      "Epoch 23/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7106 - accuracy: 0.9284\n",
      "Epoch 24/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.9215\n",
      "Epoch 25/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.9523\n",
      "Epoch 26/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.9470\n",
      "Epoch 27/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7043 - accuracy: 0.9318\n",
      "Epoch 28/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.9332\n",
      "Epoch 29/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.9384\n",
      "Epoch 30/150\n",
      "147/147 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.94 - 0s 2ms/step - loss: 0.5458 - accuracy: 0.9436\n",
      "Epoch 31/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.9374\n",
      "Epoch 32/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.9386\n",
      "Epoch 33/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.9383\n",
      "Epoch 34/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.9504\n",
      "Epoch 35/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7058 - accuracy: 0.9367\n",
      "Epoch 36/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.9315\n",
      "Epoch 37/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.9421\n",
      "Epoch 38/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.9392\n",
      "Epoch 39/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.9306\n",
      "Epoch 40/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.9510\n",
      "Epoch 41/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.7303 - accuracy: 0.9304\n",
      "Epoch 42/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.9230\n",
      "Epoch 43/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5071 - accuracy: 0.9341\n",
      "Epoch 44/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.9218\n",
      "Epoch 45/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.9312\n",
      "Epoch 46/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.9296\n",
      "Epoch 47/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.9477\n",
      "Epoch 48/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.9236\n",
      "Epoch 49/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.9461\n",
      "Epoch 50/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.9343\n",
      "Epoch 51/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.9291\n",
      "Epoch 52/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.9413\n",
      "Epoch 53/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.9438\n",
      "Epoch 54/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.9400\n",
      "Epoch 55/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.9297\n",
      "Epoch 56/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7409 - accuracy: 0.9168\n",
      "Epoch 57/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.9327\n",
      "Epoch 58/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.9361\n",
      "Epoch 59/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.9389\n",
      "Epoch 60/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.9261\n",
      "Epoch 61/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.9399\n",
      "Epoch 62/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4721 - accuracy: 0.9367\n",
      "Epoch 63/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4533 - accuracy: 0.9406\n",
      "Epoch 64/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.9375\n",
      "Epoch 65/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.9285\n",
      "Epoch 66/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.9392\n",
      "Epoch 67/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.9568: 0s - loss: 0.2759 - accu\n",
      "Epoch 68/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.9552\n",
      "Epoch 69/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.9295\n",
      "Epoch 70/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.9302\n",
      "Epoch 71/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.9419\n",
      "Epoch 72/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.9330\n",
      "Epoch 73/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5678 - accuracy: 0.9231\n",
      "Epoch 74/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.3921 - accuracy: 0.9514\n",
      "Epoch 75/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.9475\n",
      "Epoch 76/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.9384\n",
      "Epoch 77/150\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.9322\n",
      "Epoch 78/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.9478\n",
      "Epoch 79/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.9396\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.9400\n",
      "Epoch 81/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.9260\n",
      "Epoch 82/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.9351\n",
      "Epoch 83/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.9316\n",
      "Epoch 84/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.9548\n",
      "Epoch 85/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.9478\n",
      "Epoch 86/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.9578\n",
      "Epoch 87/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2923 - accuracy: 0.9530\n",
      "Epoch 88/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.9538\n",
      "Epoch 89/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2617 - accuracy: 0.9399\n",
      "Epoch 90/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2385 - accuracy: 0.9576\n",
      "Epoch 91/150\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.9450\n",
      "Epoch 92/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2407 - accuracy: 0.9405\n",
      "Epoch 93/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9494\n",
      "Epoch 94/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.9340\n",
      "Epoch 95/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2061 - accuracy: 0.9317\n",
      "Epoch 96/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.1997 - accuracy: 0.9334\n",
      "Epoch 97/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.1797 - accuracy: 0.9468\n",
      "Epoch 98/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9331\n",
      "Epoch 99/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1977 - accuracy: 0.9348\n",
      "Epoch 100/150\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 0.2037 - accuracy: 0.9286\n",
      "Epoch 101/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1691 - accuracy: 0.9395\n",
      "Epoch 102/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9307\n",
      "Epoch 103/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.9369\n",
      "Epoch 104/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.1552 - accuracy: 0.9441\n",
      "Epoch 105/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2044 - accuracy: 0.9451\n",
      "Epoch 106/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.9337\n",
      "Epoch 107/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9300\n",
      "Epoch 108/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.9212\n",
      "Epoch 109/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9337\n",
      "Epoch 110/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.9444\n",
      "Epoch 111/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9300\n",
      "Epoch 112/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9318\n",
      "Epoch 113/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9411\n",
      "Epoch 114/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9258\n",
      "Epoch 115/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9352\n",
      "Epoch 116/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9337\n",
      "Epoch 117/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9372\n",
      "Epoch 118/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9184\n",
      "Epoch 119/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9346\n",
      "Epoch 120/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.1576 - accuracy: 0.9364\n",
      "Epoch 121/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9494\n",
      "Epoch 122/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1619 - accuracy: 0.9200\n",
      "Epoch 123/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9271\n",
      "Epoch 124/150\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 0.1548 - accuracy: 0.9352\n",
      "Epoch 125/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9313\n",
      "Epoch 126/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9389\n",
      "Epoch 127/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9458\n",
      "Epoch 128/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9272\n",
      "Epoch 129/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9379\n",
      "Epoch 130/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9333\n",
      "Epoch 131/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.9268\n",
      "Epoch 132/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9367\n",
      "Epoch 133/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.1547 - accuracy: 0.9323\n",
      "Epoch 134/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.1404 - accuracy: 0.9509\n",
      "Epoch 135/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9470\n",
      "Epoch 136/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9319\n",
      "Epoch 137/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9325\n",
      "Epoch 138/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1494 - accuracy: 0.9540\n",
      "Epoch 139/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9422\n",
      "Epoch 140/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9018\n",
      "Epoch 141/150\n",
      "147/147 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.9293\n",
      "Epoch 142/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9471\n",
      "Epoch 143/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9611\n",
      "Epoch 144/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9381\n",
      "Epoch 145/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9201\n",
      "Epoch 146/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9321\n",
      "Epoch 147/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9328\n",
      "Epoch 148/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.1597 - accuracy: 0.9398\n",
      "Epoch 149/150\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.9411\n",
      "Epoch 150/150\n",
      "147/147 [==============================] - 0s 2ms/step - loss: 0.2507 - accuracy: 0.9483\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=150, batch_size=5)\n",
    "y_pred= model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9783\n",
      "Accuracy: 97.83\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
